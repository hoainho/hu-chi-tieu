# run_agent.py
from qwen_agent.agents import Assistant

# Cáº¥u hÃ¬nh model: Ollama expose OpenAI-compatible API á»Ÿ localhost:11434
llm_cfg = {
    "model": "qwen3-coder:30b",         # TÃªn model Ä‘Ãºng theo Ollama
    "model_server": "http://localhost:11434/v1",  # API base cá»§a Ollama
    "api_key": "EMPTY"                  # Ollama khÃ´ng cáº§n key, nhÆ°ng Qwen-Agent yÃªu cáº§u field
}

# MÃ´ táº£ vai trÃ²
system_instruction = "You are a professional coding assistant. Help write, debug, and explain code."

agent = Assistant(
    llm_cfg=llm_cfg,
    system_instruction=system_instruction
)

# Test CLI chat
print("ðŸš€ Qwen Agent (Coding Mode) is ready!\n")
while True:
    prompt = input("ðŸ‘¤ You: ")
    if prompt.lower() in ["exit", "quit"]:
        break
    response = agent.chat(prompt)
    print("ðŸ¤– Agent:", response)
